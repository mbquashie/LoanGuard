{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import loan_default_data_processor as lp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data with shape: (1136033, 180)\n",
      "Features shape: (1136033, 179), Target shape: (1136033,)\n",
      "Training set shape: (795223, 179), Testing set shape: (340810, 179)\n",
      "Training target distribution:\n",
      "loan_outcome\n",
      "0    644485\n",
      "1    150738\n",
      "Name: count, dtype: int64\n",
      "Testing target distribution:\n",
      "loan_outcome\n",
      "0    276208\n",
      "1     64602\n",
      "Name: count, dtype: int64\n",
      "Numerical columns to scale: ['loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'loan_term', 'int_rate', 'installment', 'annual_inc', 'dti', 'delinq_2yrs', 'fico_range_low', 'fico_range_high', 'inq_last_6mths', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', 'last_pymnt_amnt', 'last_fico_range_high', 'last_fico_range_low', 'collections_12_mths_ex_med', 'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', 'total_rev_hi_lim', 'acc_open_past_24mths', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'chargeoff_within_12_mths', 'delinq_amnt', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl', 'mort_acc', 'mths_since_recent_bc', 'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl', 'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl', 'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m', 'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m', 'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies', 'tax_liens', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit', 'total_il_high_credit_limit', 'employment_length', 'earliest_cr_line_year', 'issue_d_year', 'last_pymnt_d_year', 'last_credit_pull_d_year']\n",
      "Rescaling complete.\n",
      "Balanced training set shape: (301476, 179), (301476,)\n",
      "Balanced training target distribution:\n",
      "loan_outcome\n",
      "0    150738\n",
      "1    150738\n",
      "Name: count, dtype: int64\n",
      "Processed data saved to 'processed_data' directory.\n",
      "Scaler and undersampler saved to 'models' directory.\n",
      "Data processing complete.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load Processed Data\n",
    "processed_data_input_path = \"/Users/mbq/Desktop/Project_Erdos/Data/processed_loan_data.csv\"\n",
    "df = lp.load_processed_data(processed_data_input_path)\n",
    "print(f\"Loaded data with shape: {df.shape}\")\n",
    "\n",
    "# Step 2: Split Features and Target\n",
    "X, y = lp.split_features_target(df, target_column='loan_outcome')\n",
    "print(f\"Features shape: {X.shape}, Target shape: {y.shape}\")\n",
    "\n",
    "# Step 3: Perform Train-Test Split with Stratification\n",
    "X_train, X_test, y_train, y_test = lp.perform_train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "print(f\"Training set shape: {X_train.shape}, Testing set shape: {X_test.shape}\")\n",
    "print(f\"Training target distribution:\\n{y_train.value_counts()}\")\n",
    "print(f\"Testing target distribution:\\n{y_test.value_counts()}\")\n",
    "\n",
    "# Step 4: Identify Numerical Columns for Rescaling\n",
    "numerical_cols = X_train.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "print(f\"Numerical columns to scale: {numerical_cols}\")\n",
    "\n",
    "# Step 5: Rescale Numerical Features\n",
    "X_train_scaled, X_test_scaled, scaler = lp.rescale_features(X_train, X_test, numerical_cols)\n",
    "print(\"Rescaling complete.\")\n",
    "\n",
    "# Step 6: Balance the Training Data using Undersampling\n",
    "X_train_balanced, y_train_balanced, undersampler = lp.balance_training_data(X_train_scaled, y_train, random_state=42)\n",
    "print(f\"Balanced training set shape: {X_train_balanced.shape}, {y_train_balanced.shape}\")\n",
    "print(f\"Balanced training target distribution:\\n{y_train_balanced.value_counts()}\")\n",
    "\n",
    "# Step 7: Save the Processed Data\n",
    "lp.save_processed_data(X_train_balanced, X_test_scaled, y_train_balanced, y_test, processed_dir='processed_data')\n",
    "\n",
    "# Step 8: Save the Scaler and Undersampler Objects\n",
    "lp.save_scaler_and_sampler(scaler, undersampler, model_dir='models')\n",
    "\n",
    "print(\"Data processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
